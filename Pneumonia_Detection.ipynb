{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 23812,
          "sourceType": "datasetVersion",
          "datasetId": 17810
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SharoonSharif/Pneumonia-Detection-using-Chest-X-Ray/blob/main/Pneumonia_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'chest-xray-pneumonia:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F17810%2F23812%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241009%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241009T230829Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7f0fa52c658ba3b11af8477fee6ba23708250aefe5c70a12d7263f418c64b16271def111632bc4326e28305b16c1294367fa0b405db11ab7297fe488a750d9cc62007e0685954f1f7f1a3a2764fd8088c5086ddae7d63cc85cb143909b2e9bdc3e6f8e5b515a2ba4399eb6266a72c8e32f961cb3bff9d74b74d95ed5e59bfe05c276fc8a4d5890878fcff3e22f6fd90ec23a177aa9318ec3d0cf975efd8b4a8087caa6ef111251b457a79adc277f716b9a3529e6ed787460c9fffd4e89d8b88740068ec8f915ba170e373aab6f55a803e49daa209752391f8536a90bec8da9bbf26dc77b1a471faafdbacf212c79b790313b3b32ee5478eece1ead7465d1b086'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "J8rlAkDMiol3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\">Importing Dependencies</div>"
      ],
      "metadata": {
        "id": "gopUo2Lysa11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "id": "PplFtD9msa12",
        "execution": {
          "iopub.status.busy": "2024-09-23T14:01:57.182433Z",
          "iopub.execute_input": "2024-09-23T14:01:57.183162Z",
          "iopub.status.idle": "2024-09-23T14:02:10.570587Z",
          "shell.execute_reply.started": "2024-09-23T14:01:57.183118Z",
          "shell.execute_reply": "2024-09-23T14:02:10.569786Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\">Dataset Description</div>\n",
        "\n",
        "\n",
        "<div style=\"background-color: #76B1ED; color: #0a0a85; padding: 10px; border-radius: 10px;font-family: 'Arial', sans-serif; font-size: 15px; margin: 5px;\">\n",
        "<p>The dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia/Normal).\n",
        "\n",
        "Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children’s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients’ routine clinical care.\n",
        "\n",
        "For the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n",
        "<p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "OWMxpPgEsa12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\">Loading Dataset</div>"
      ],
      "metadata": {
        "id": "eznNCAz9sa13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels for image categories\n",
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "img_size = 128\n",
        "\n",
        "def loading_training_data(data_dir):\n",
        "    data = []\n",
        "    labels_list = []\n",
        "\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "            resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
        "            data.append(resized_arr)\n",
        "            labels_list.append(class_num)\n",
        "\n",
        "    return np.array(data), np.array(labels_list)\n",
        "\n",
        "# Load data for training, testing, and validation\n",
        "train_data, train_labels = loading_training_data('/kaggle/input/chest-xray-pneumonia/chest_xray/train')\n",
        "test_data, test_labels = loading_training_data('/kaggle/input/chest-xray-pneumonia/chest_xray/test')"
      ],
      "metadata": {
        "id": "U2ZLSHRZsa13",
        "execution": {
          "iopub.status.busy": "2024-09-23T14:02:10.572079Z",
          "iopub.execute_input": "2024-09-23T14:02:10.572621Z",
          "iopub.status.idle": "2024-09-23T14:03:31.738449Z",
          "shell.execute_reply.started": "2024-09-23T14:02:10.572586Z",
          "shell.execute_reply": "2024-09-23T14:03:31.737578Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\">Visualizing Data</div>"
      ],
      "metadata": {
        "id": "LOfSb00Msa14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_indices = np.random.choice(len(train_data), 8, replace=False)\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(train_data[idx], cmap='magma')\n",
        "    plt.title('Pneumonia' if train_labels[idx] == 0 else 'Normal')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle(\"Pneumonia Sample Images\", size=18)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-23T14:03:31.739589Z",
          "iopub.execute_input": "2024-09-23T14:03:31.739916Z",
          "iopub.status.idle": "2024-09-23T14:03:32.788408Z",
          "shell.execute_reply.started": "2024-09-23T14:03:31.739882Z",
          "shell.execute_reply": "2024-09-23T14:03:32.787422Z"
        },
        "trusted": true,
        "id": "jpVG0kTliol-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data Distribution\n",
        "labels_df = pd.DataFrame({\"Labels\":train_labels})\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "colors = sns.light_palette(\"#76B1ED\", n_colors=7)\n",
        "sns.countplot(data = labels_df, x='Labels', palette=[colors[3], colors[6]])\n",
        "plt.xticks(ticks=[0, 1], labels=['Pneumonia', 'Normal'])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-23T14:03:32.790513Z",
          "iopub.execute_input": "2024-09-23T14:03:32.790837Z",
          "iopub.status.idle": "2024-09-23T14:03:32.983976Z",
          "shell.execute_reply.started": "2024-09-23T14:03:32.790804Z",
          "shell.execute_reply": "2024-09-23T14:03:32.982938Z"
        },
        "trusted": true,
        "id": "soN6XFDciol-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #76B1ED; color: #0a0a85; padding: 10px; border-radius: 10px;font-family: 'Arial', sans-serif; font-size: 15px; margin: 5px;\">The training data is imbalanced, with fewer examples for Normal compared to Pneumonia. To address this issue and increase the number of training examples, we will employ data augmentation techniques.</div>"
      ],
      "metadata": {
        "id": "_-xWOc3Qsa15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\">Data Preprocessing</div>"
      ],
      "metadata": {
        "id": "gGvJklWCiol_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "X_train = np.array(train_data) / 255\n",
        "X_test = np.array(test_data) / 255"
      ],
      "metadata": {
        "id": "3Lqw68G-sa19",
        "execution": {
          "iopub.status.busy": "2024-09-23T14:03:32.985222Z",
          "iopub.execute_input": "2024-09-23T14:03:32.985565Z",
          "iopub.status.idle": "2024-09-23T14:03:33.255849Z",
          "shell.execute_reply.started": "2024-09-23T14:03:32.98553Z",
          "shell.execute_reply": "2024-09-23T14:03:33.254806Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #76B1ED; color: #0a0a85; padding: 10px; border-radius: 10px;font-family: 'Arial', sans-serif; font-size: 15px; margin: 5px;\">Grayscale normalization is applied to minimize the impact of illumination variations. Also, the CNN converges more quickly on data scaled to the range [0..1] compared to the original range of [0..255].</div>"
      ],
      "metadata": {
        "id": "5xhQPzFOsa17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "img_size = 128\n",
        "\n",
        "# Reshape the grayscale images to 128x128x1\n",
        "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
        "X_test = X_test.reshape(-1, img_size, img_size, 1)\n",
        "\n",
        "# Convert grayscale to RGB by duplicating the single channel 3 times\n",
        "X_train = np.repeat(X_train, 3, axis=-1)\n",
        "X_test = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "# Convert labels to numpy arrays\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "print(X_train.shape)  # This should now show (num_samples, 128, 128, 3)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-23T14:03:33.256979Z",
          "iopub.execute_input": "2024-09-23T14:03:33.257305Z",
          "iopub.status.idle": "2024-09-23T14:03:34.076725Z",
          "shell.execute_reply.started": "2024-09-23T14:03:33.257271Z",
          "shell.execute_reply": "2024-09-23T14:03:34.075652Z"
        },
        "trusted": true,
        "id": "AK5qw2uQiomA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #76B1ED; color: #0a0a85; padding: 10px; border-radius: 10px;font-family: 'Arial', sans-serif; font-size: 15px; margin: 5px;\">Reshaping the grayscale images to 128x128x1 ensures they conform to a standard size, and the added single-channel dimension allows the CNN to process grayscale images properly. Converting the grayscale images to RGB by duplicating the single channel three times ensures compatibility with pre-trained models, like MobileNet, that expect three-channel (RGB) inputs. Finally, converting the labels to NumPy arrays ensures they are in a format suitable for model training.</div>"
      ],
      "metadata": {
        "id": "gfalXCciiomA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the validation size\n",
        "val_size = 0.2\n",
        "\n",
        "# Split the data\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train, y_train, test_size=val_size, random_state=21)\n",
        "\n",
        "# Check the shapes\n",
        "print(\"Training data shape:\", X_train_split.shape)\n",
        "print(\"Validation data shape:\", X_val_split.shape)\n",
        "print(\"Training labels shape:\", y_train_split.shape)\n",
        "print(\"Validation labels shape:\", y_val_split.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-23T14:03:34.07816Z",
          "iopub.execute_input": "2024-09-23T14:03:34.07865Z",
          "iopub.status.idle": "2024-09-23T14:03:34.666932Z",
          "shell.execute_reply.started": "2024-09-23T14:03:34.078605Z",
          "shell.execute_reply": "2024-09-23T14:03:34.66599Z"
        },
        "trusted": true,
        "id": "v3gNvRXYiomA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #76B1ED; color: #0a0a85; padding: 10px; border-radius: 10px;font-family: 'Arial', sans-serif; font-size: 15px; margin: 5px;\">Explanation: The train_test_split function is used to divide the dataset into training and validation sets. The validation set size is set to 20% of the original data. This split ensures the model can be trained on 80% of the data while evaluating its performance on the remaining 20%. The random_state=21 guarantees that the split is reproducible across different runs, providing consistency when evaluating the model's performance.</div>"
      ],
      "metadata": {
        "id": "XjDOu6SUiomA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\">Data Augmentation</div>"
      ],
      "metadata": {
        "id": "jjGRMwJxsa1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Data Augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                    rotation_range = 30,\n",
        "                    zoom_range = 0.2,\n",
        "                    width_shift_range=0.1,\n",
        "                    height_shift_range=0.1,\n",
        "                    horizontal_flip = True,\n",
        "                    shear_range=0.2,\n",
        "                    fill_mode='nearest',\n",
        "                 )\n",
        "\n",
        "\n",
        "data_generator.fit(X_train)"
      ],
      "metadata": {
        "id": "jGlBFhEosa1-",
        "execution": {
          "iopub.status.busy": "2024-09-23T14:03:34.668196Z",
          "iopub.execute_input": "2024-09-23T14:03:34.668593Z",
          "iopub.status.idle": "2024-09-23T14:03:35.412098Z",
          "shell.execute_reply.started": "2024-09-23T14:03:34.668546Z",
          "shell.execute_reply": "2024-09-23T14:03:35.411079Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #76B1ED; color: #0a0a85; padding: 10px; border-radius: 10px;font-family: 'Arial', sans-serif; font-size: 15px; margin: 5px;\">Performing data augmentation by applying transformations like rotation, zoom, shifts, and flips. This helps increase the diversity of training data, which improves the model's robustness and generalization by reducing overfitting.</div>"
      ],
      "metadata": {
        "id": "IlVDScQFiomA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\"> EfficientNetB4</div>"
      ],
      "metadata": {
        "id": "QJKIiL5riomB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (128, 128, 3)  # Directly using RGB input\n",
        "\n",
        "# Load MobileNet with pre-trained weights, specifying the input shape and without the top classification layers\n",
        "mobilenet_base = EfficientNetB4(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "\n",
        "# Add Global Average Pooling to reduce dimensionality\n",
        "x = mobilenet_base.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "x = Dense(96,activation='relu', kernel_regularizer=l2(0.05))(x)\n",
        "x = Dropout(0.7)(x)\n",
        "# Add the final Dense layer for binary classification\n",
        "output_layer = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.05))(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=mobilenet_base.input, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Show model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-23T14:03:35.413338Z",
          "iopub.execute_input": "2024-09-23T14:03:35.413635Z",
          "iopub.status.idle": "2024-09-23T14:03:40.135798Z",
          "shell.execute_reply.started": "2024-09-23T14:03:35.413604Z",
          "shell.execute_reply": "2024-09-23T14:03:40.134917Z"
        },
        "trusted": true,
        "id": "wnEPt8EaiomB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #76B1ED; color: #0a0a85; padding: 10px; border-radius: 10px;font-family: 'Arial', sans-serif; font-size: 15px; margin: 5px;\">EfficientNetB4 is loaded with pre-trained ImageNet weights to leverage transfer learning, ensuring the model starts with knowledge from large-scale datasets. Global Average Pooling is used to reduce dimensionality and minimize overfitting while retaining spatial information. Dropout layers with a rate of 0.7 are added to prevent overfitting by randomly disabling nodes during training. The Dense layers include L2 regularization to add further regularization, controlling model complexity. The final Dense layer uses a sigmoid activation for binary classification, outputting a probability. The model is compiled with Adam optimizer and binary cross-entropy loss, ideal for binary classification tasks.</div>"
      ],
      "metadata": {
        "id": "Sa6Zo40eiomB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "model.fit(X_train_split, y_train_split, epochs=15,\n",
        "          validation_data=data_generator.flow(X_val_split, y_val_split),\n",
        "          batch_size=64, class_weight=class_weights)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-23T14:05:25.242915Z",
          "iopub.execute_input": "2024-09-23T14:05:25.24333Z",
          "iopub.status.idle": "2024-09-23T14:15:36.702129Z",
          "shell.execute_reply.started": "2024-09-23T14:05:25.24329Z",
          "shell.execute_reply": "2024-09-23T14:15:36.701145Z"
        },
        "trusted": true,
        "id": "viWTEKqqiomB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #76B1ED; color: #0a0a85; padding: 10px; border-radius: 10px;font-family: 'Arial', sans-serif; font-size: 15px; margin: 5px;\">The class_weight function computes the class weights to balance the training process when dealing with imbalanced datasets, ensuring that the minority class is given more importance. The model is then trained using the fit function, with the class weights passed to ensure balanced learning. The data_generator.flow is used to feed the validation data in batches, and batch_size=64 helps manage memory usage. The training runs for 15 epochs, and the validation data is used to monitor the model's performance after each epoch.</div>"
      ],
      "metadata": {
        "id": "Vu4iCDhviomB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\">Training & Validation Metrics Visualization</div>"
      ],
      "metadata": {
        "id": "dSA28Mfasa2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve metrics from the training history\n",
        "history = model.history.history  # Access the 'history' dictionary\n",
        "\n",
        "train_acc = history['accuracy']\n",
        "train_loss = history['loss']\n",
        "val_acc = history['val_accuracy']\n",
        "val_loss = history['val_loss']\n",
        "\n",
        "# Epochs\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "# Create a figure and axes for the plots\n",
        "fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[0].plot(epochs, train_acc, 'o-', color='darkgreen', label='Training Accuracy', markersize=8)\n",
        "ax[0].plot(epochs, val_acc, 's--', color='darkred', label='Validation Accuracy', markersize=8)\n",
        "ax[0].set_title('Training vs. Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=14)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=14)\n",
        "ax[0].legend()\n",
        "ax[0].grid(True)\n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[1].plot(epochs, train_loss, 'o-', color='darkblue', label='Training Loss', markersize=8)\n",
        "ax[1].plot(epochs, val_loss, 's--', color='orange', label='Validation Loss', markersize=8)\n",
        "ax[1].set_title('Training vs. Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=14)\n",
        "ax[1].set_ylabel('Loss', fontsize=14)\n",
        "ax[1].legend()\n",
        "ax[1].grid(True)\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-23T14:15:36.711426Z",
          "iopub.execute_input": "2024-09-23T14:15:36.71178Z",
          "iopub.status.idle": "2024-09-23T14:15:37.382848Z",
          "shell.execute_reply.started": "2024-09-23T14:15:36.711732Z",
          "shell.execute_reply": "2024-09-23T14:15:37.381886Z"
        },
        "trusted": true,
        "id": "jg4idOy6iomC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color: #76B1ED; color: white; padding: 10px; border-radius: 10px;text-align: center;font-family: 'Arial', sans-serif; font-size: 30px; margin: 5px; font-weight:bold;\">Model Performance on Testing Data</div>"
      ],
      "metadata": {
        "id": "7yg7B-6biomC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(X_test,y_test)\n",
        "print(\"==\"*20)\n",
        "print(f\"Accuracy - {evaluation[1]*100}%\")\n",
        "print(f\"Loss - {evaluation[0]}\")\n",
        "print(\"==\"*20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-23T14:16:28.577721Z",
          "iopub.execute_input": "2024-09-23T14:16:28.578146Z",
          "iopub.status.idle": "2024-09-23T14:16:35.935142Z",
          "shell.execute_reply.started": "2024-09-23T14:16:28.578107Z",
          "shell.execute_reply": "2024-09-23T14:16:35.93419Z"
        },
        "trusted": true,
        "id": "hgtbP83SiomC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on Test data\n",
        "predictions = model.predict(X_test)\n",
        "predictions = predictions.reshape(1,-1)[0]"
      ],
      "metadata": {
        "id": "5QOh2zuIsa2B",
        "execution": {
          "iopub.status.busy": "2024-09-23T14:16:51.508925Z",
          "iopub.execute_input": "2024-09-23T14:16:51.509327Z",
          "iopub.status.idle": "2024-09-23T14:17:08.352799Z",
          "shell.execute_reply.started": "2024-09-23T14:16:51.509288Z",
          "shell.execute_reply": "2024-09-23T14:17:08.351811Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select 8 indices from the test set\n",
        "random_indices = np.random.choice(len(X_test), 8, replace=False)\n",
        "\n",
        "# Define the figure size\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Iterate through the selected indices\n",
        "for i, idx in enumerate(random_indices):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(X_test[idx].reshape(128, 128,3), cmap='magma', interpolation='none')\n",
        "\n",
        "    # Set the title with predicted and actual classes\n",
        "    plt.title(f\"Predicted: {round(predictions[idx])}   Actual: {y_test[idx]}\", fontsize=10)\n",
        "\n",
        "    # Remove x and y ticks\n",
        "    plt.axis('off')\n",
        "\n",
        "# Set the main title for the figure\n",
        "plt.suptitle(\"Sample Test Images with Predictions\", size=18)\n",
        "\n",
        "# Adjust layout to prevent overlapping\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S_ACqGCCsa2G",
        "execution": {
          "iopub.status.busy": "2024-09-23T14:17:08.35425Z",
          "iopub.execute_input": "2024-09-23T14:17:08.354579Z",
          "iopub.status.idle": "2024-09-23T14:17:09.02569Z",
          "shell.execute_reply.started": "2024-09-23T14:17:08.354543Z",
          "shell.execute_reply": "2024-09-23T14:17:09.024688Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t77RCYkfiomD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}